{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_generation_notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN6WYtIiqAwM",
        "outputId": "20df87d8-cca1-4409-b810-558ddb020c85"
      },
      "source": [
        "pip install markovify"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting markovify\n",
            "  Downloading https://files.pythonhosted.org/packages/56/18/fdc3e6e0a55e10a4457846987e6b48587c0dbf616baae582501da7396b82/markovify-0.9.0.tar.gz\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/25/723487ca2a52ebcee88a34d7d1f5a4b80b793f179ee0f62d5371938dfa01/Unidecode-1.2.0-py2.py3-none-any.whl (241kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 6.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: markovify\n",
            "  Building wheel for markovify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for markovify: filename=markovify-0.9.0-cp36-none-any.whl size=18475 sha256=67d70d25abab30308cdccdc90a8e7edbe21a0bb638f3dd87ffbc39ca0f1f90bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/59/5b/04c5f27d57977580c1122fa69a69c327dede5a30f9dac54c55\n",
            "Successfully built markovify\n",
            "Installing collected packages: unidecode, markovify\n",
            "Successfully installed markovify-0.9.0 unidecode-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4z-w-4LMpxgj",
        "outputId": "8d78bfc0-ed80-4fe5-ba59-c00280af5dd8"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sqlalchemy import create_engine\n",
        "import nltk\n",
        "import spacy\n",
        "import markovify\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action=\"ignore\")\n",
        "\n",
        "!python -m spacy download en"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (53.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-fOZTJPqPyE"
      },
      "source": [
        "postgres_user = 'dsbc_student'\n",
        "postgres_pw = '7*.8G9QH21'\n",
        "postgres_host = '142.93.121.174'\n",
        "postgres_port = '5432'\n",
        "postgres_db = 'twitter_sentiment'\n",
        "\n",
        "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
        "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
        "\n",
        "tweets_df = pd.read_sql_query('select * from twitter',con=engine)\n",
        "\n",
        "# no need for an open connection, as we're only doing a single query\n",
        "engine.dispose()\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "xsANiDscqbBU",
        "outputId": "f94d52e2-7020-459d-e81f-5f3b878fffb1"
      },
      "source": [
        "tweets_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>None</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>None</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>None</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>None</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index            tweet_id  ... tweet_location               user_timezone\n",
              "0      0  570306133677760513  ...           None  Eastern Time (US & Canada)\n",
              "1      1  570301130888122368  ...           None  Pacific Time (US & Canada)\n",
              "2      2  570301083672813571  ...      Lets Play  Central Time (US & Canada)\n",
              "3      3  570301031407624196  ...           None  Pacific Time (US & Canada)\n",
              "4      4  570300817074462722  ...           None  Pacific Time (US & Canada)\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlhxpuJ4qt53"
      },
      "source": [
        "### 1. First, do some data preprocessing to clean up the data as necessary. You can use your solution to the assignment of the Text preprocessing checkpoint.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kWzXJ3wqtFt"
      },
      "source": [
        "nlp = spacy.load('en')\n",
        "\n",
        "# below is necessary to avoid memory errors with spacy\n",
        "nlp.max_length = 20000000\n",
        "\n",
        "# all the processing work is done below, so it may take a while \n",
        "\n",
        "twitter_doc = nlp(\" \".join(tweets_df.text))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J33EtgM3rzPm"
      },
      "source": [
        "### Train a Markov chain model by using only the negative sentiment tweets. Generate some random sentences. Do the generated sentences exhibit the same negative sentiment?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xl0iEeJZryif",
        "outputId": "cbbf0e6a-a787-480e-8425-46d3bdd3e99a"
      },
      "source": [
        "twitter_negs = tweets_df.loc[tweets_df.airline_sentiment == 'negative'].text\n",
        "twitter_negs"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3        @VirginAmerica it's really aggressive to blast...\n",
              "4        @VirginAmerica and it's a really big bad thing...\n",
              "5        @VirginAmerica seriously would pay $30 a fligh...\n",
              "15           @VirginAmerica SFO-PDX schedule is still MIA.\n",
              "17       @VirginAmerica  I flew from NYC to SFO last we...\n",
              "                               ...                        \n",
              "14631    @AmericanAir How do I change my flight if the ...\n",
              "14633    @AmericanAir thx for nothing on getting us out...\n",
              "14635    @AmericanAir my flight was Cancelled Flightled...\n",
              "14636    @AmericanAir leaving over 20 minutes Late Flig...\n",
              "14638    @AmericanAir you have my money, you change my ...\n",
              "Name: text, Length: 9178, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw2qMeyBtjEQ"
      },
      "source": [
        "# processing work done here\n",
        "\n",
        "neg_tweets_doc = nlp(\" \".join(twitter_negs))\n",
        "\n",
        "neg_tweets_sents = \" \".join([sent.text for sent in neg_tweets_doc.sents if len(sent.text) > 1 ])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXgsZO7mt1N-",
        "outputId": "ef0bcffd-a9be-43ad-c0fb-35f62ccd1175"
      },
      "source": [
        "neg_tweets_gen = markovify.Text(neg_tweets_sents,state_size = 3)\n",
        "\n",
        "# three randomly generated sentences \n",
        "for i in range(3):\n",
        "  print(neg_tweets_gen.make_sentence(tries=100))\n",
        "\n",
        "print('\\n'+'-'*40+'\\n')\n",
        "\n",
        "# tree randomly generated sentences of no more than 100 characters\n",
        "\n",
        "for i in range(3):\n",
        "  print(neg_tweets_gen.make_short_sentence(100,tries=100))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@SouthwestAir Trying to get my boyfriend booked on the same flight I was put on flight tomorrow AM, arriving home at 4 pm.\n",
            "@united I'm not sure how you guys don't know where my bags are?\n",
            "@united after 2 days - for multiple hours on hold got rebooked on on us airways by you guys but the flight I have been loyal to Southwest from the beginning but very unhappy about your devaluation.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "@JetBlue what's going on with United's Mileage Program?\n",
            "@SouthwestAir Flight Cancelled Flighted, two hours on the phone who knew what they were doing.\n",
            "What's up with the wait times on your customer service phone off the hook!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJEju4tovIgP"
      },
      "source": [
        "### 3. Repeat the previous task, but this time, use only the positive sentiment tweets. Generate some random sentences and observe whether they exhibit positive sentiment or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xd-nTEdPumlV",
        "outputId": "58615c83-25d0-40dd-ae0e-d3bc4631989e"
      },
      "source": [
        "twitter_pos = tweets_df.loc[tweets_df.airline_sentiment == 'positive'].text\n",
        "twitter_pos"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1        @VirginAmerica plus you've added commercials t...\n",
              "6        @VirginAmerica yes, nearly every time I fly VX...\n",
              "8          @virginamerica Well, I didn't…but NOW I DO! :-D\n",
              "9        @VirginAmerica it was amazing, and arrived an ...\n",
              "11       @VirginAmerica I &lt;3 pretty graphics. so muc...\n",
              "                               ...                        \n",
              "14621    @AmericanAir I love your company and your staf...\n",
              "14625    @AmericanAir Love the new planes for the JFK-L...\n",
              "14627    @AmericanAir Flight 236 was great. Fantastic c...\n",
              "14630    Thank you. “@AmericanAir: @jlhalldc Customer R...\n",
              "14632                          @AmericanAir Thanks! He is.\n",
              "Name: text, Length: 2363, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFk600vSvRMa"
      },
      "source": [
        "# processing work done here\n",
        "\n",
        "pos_tweets_doc = nlp(\" \".join(twitter_pos))\n",
        "\n",
        "pos_tweets_sents = \" \".join([sent.text for sent in pos_tweets_doc.sents if len(sent.text) > 1 ])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAHZBKVjvXws",
        "outputId": "752b4fec-786a-4d3b-b141-496fbfb73ea4"
      },
      "source": [
        "pos_tweets_gen = markovify.Text(pos_tweets_sents,state_size = 3)\n",
        "\n",
        "# three randomly generated sentences \n",
        "for i in range(3):\n",
        "  print(pos_tweets_gen.make_sentence(tries=100))\n",
        "\n",
        "print('\\n'+'-'*40+'\\n')\n",
        "\n",
        "# tree randomly generated sentences of no more than 100 characters\n",
        "\n",
        "for i in range(3):\n",
        "  print(pos_tweets_gen.make_short_sentence(100,tries=100))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@SouthwestAir - I just had a great flight #4223 with Damion!\n",
            "#flyfi http://t.co/8jceDiKY9U @JetBlue thanks @JetBlue Then en route to LHR @united thank you!\n",
            "@SouthwestAir @DeltaPoints hey at least you guys are and this rolled across.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Thank you to the great crew on flight 206 is awesome!\n",
            "@SouthwestAir lol I already am ! I am a happy customer @united thanx so much.\n",
            "2 mths waiting @AmericanAir to speak to someone things got fixed very quick.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "el4reSE-vl2x"
      },
      "source": [
        "### 4. Now, train your Markov chain model using all of the tweets. Generate some random sentences. Can you say something systematic about the sentiments of the generated tweets?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rS_3F_t3xRca"
      },
      "source": [
        "twitter_sents = \" \".join([sent.text for sent in twitter_doc.sents if len(sent.text) > 1 ])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9OAQXtnxn-z",
        "outputId": "5f21e148-8d06-43a7-a73e-d11d2ae642df"
      },
      "source": [
        "tweets_gen = markovify.Text(twitter_sents,state_size=3)\n",
        "\n",
        "# three randomly generated sentences \n",
        "for i in range(3):\n",
        "  print(tweets_gen.make_sentence(tries=100))\n",
        "\n",
        "print('\\n'+'-'*40+'\\n')\n",
        "\n",
        "# tree randomly generated sentences of no more than 100 characters\n",
        "\n",
        "for i in range(3):\n",
        "  print(tweets_gen.make_short_sentence(100,tries=100))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#loveisintheair http://t.co/DoCmvoTWTI @JetBlue She claimed that she did, but I was the last drop for me; plan to avoid AA as possible.\n",
            "@JetBlue some woman stole my seat on the plane now we need to go to work tomorrow am.\n",
            "@united I took care of it @USAirways I have corporate-paid travel in April.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Was able to get on that, please.\n",
            "I made a reservation online but I didn't make the Flight Booking Problems.\n",
            "@united: thanks for the show!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVDwvzpmx--q"
      },
      "source": [
        "We can see both positive and negative tweets this time"
      ]
    }
  ]
}